

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon.png">
  <link rel="icon" href="/img/icon.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Dufolk">
  <meta name="keywords" content="">
  
    <meta name="description" content="在上一节中，我们通过Q-learning算法实现了一个能够自主学习玩贪吃蛇的强化学习智能体。虽然Q-learning算法在小规模的状态空间中表现良好，但它的局限性也非常明显。由于Q-table的大小随状态空间的增长呈指数级扩展，在面对更复杂或连续的环境时，Q-learning会因存储和计算的限制而难以适用。而贪吃蛇游戏的状态空间虽然经过简化，但仍然存在较大的扩展潜力。 在本章中，我们将基于前文提到">
<meta property="og:type" content="article">
<meta property="og:title" content="基于强化学习的贪吃蛇游戏(四)——基于DQN算法的智能体">
<meta property="og:url" content="http://dufolk.github.io/2024/12/19/snake-3/index.html">
<meta property="og:site_name" content="随机过程集">
<meta property="og:description" content="在上一节中，我们通过Q-learning算法实现了一个能够自主学习玩贪吃蛇的强化学习智能体。虽然Q-learning算法在小规模的状态空间中表现良好，但它的局限性也非常明显。由于Q-table的大小随状态空间的增长呈指数级扩展，在面对更复杂或连续的环境时，Q-learning会因存储和计算的限制而难以适用。而贪吃蛇游戏的状态空间虽然经过简化，但仍然存在较大的扩展潜力。 在本章中，我们将基于前文提到">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://dufolk.github.io/img/snake/cover.png">
<meta property="article:published_time" content="2024-12-19T07:11:52.000Z">
<meta property="article:modified_time" content="2024-12-29T12:54:56.759Z">
<meta property="article:author" content="Dufolk">
<meta property="article:tag" content="理论学习">
<meta property="article:tag" content="强化学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://dufolk.github.io/img/snake/cover.png">
  
  
  
  <title>基于强化学习的贪吃蛇游戏(四)——基于DQN算法的智能体 - 随机过程集</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/scrollAnimation.css">
<link rel="stylesheet" href="/css/selection.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"dufolk.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"§"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"a5SSXXtCxO91qRKFkjVQMkDi-MdYXbMMI","app_key":"4AKbD6prikTmwFEX320HpvXv","server_url":null,"path":"window.location.pathname","ignore_local":false,"security":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>随机过程集</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>本人</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/page_banner.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">基于强化学习的贪吃蛇游戏(四)——基于DQN算法的智能体</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-19 15:11" pubdate>
          2024年12月19日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          28 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">基于强化学习的贪吃蛇游戏(四)——基于DQN算法的智能体</h1>
            
            
              <div class="markdown-body">
                
                <p>在上一节中，我们通过Q-learning算法实现了一个能够自主学习玩贪吃蛇的强化学习智能体。虽然Q-learning算法在小规模的状态空间中表现良好，但它的局限性也非常明显。由于Q-table的大小随状态空间的增长呈指数级扩展，在面对更复杂或连续的环境时，Q-learning会因存储和计算的限制而难以适用。而贪吃蛇游戏的状态空间虽然经过简化，但仍然存在较大的扩展潜力。</p>
<p>在本章中，我们将基于<a href="https://dufolk.github.io/2024/12/19/snake-1/">前文</a>提到的DQN算法设计一个智能体，并将其嵌入到贪吃蛇游戏中。我们会详细讲解DQN的实现步骤以及如何利用深度神经网络对贪吃蛇游戏进行训练。通过DQN，智能体将能够在更复杂的状态空间中学习到合适的策略。</p>
<span id="more"></span>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mtext>😄</mtext></msub><mtext>😅</mtext><mo>=</mo><mtext>💧</mtext></mrow><annotation encoding="application/x-tex">\log_{😄}😅=💧
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9386em;vertical-align:-0.2441em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.2441em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">😄</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">😅</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0em;"></span><span class="mord">💧</span></span></span></span></span></p>
<h3 id="状态建模">状态建模</h3>
<p>不同于Q-learning直接将状态映射到Q-table的索引，DQN需要将游戏状态表示为一个张量，作为神经网络的输入。通过这种方式，DQN能够处理更复杂的状态空间，并通过深度神经网络学习状态与动作之间的映射。<br>
在本项目中，我们将贪吃蛇游戏的状态建模为一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">3 \times 12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>的输入张量，如图1所示：</p>
<ul>
<li>通道1：蛇头位置。使用一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>的矩阵表示蛇头的位置，矩阵中蛇头所在的格子值为1，其余格子值为0。</li>
<li>通道2：蛇身位置。使用一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>的矩阵表示蛇身的位置（不包括蛇头），矩阵中蛇身所在的格子值为1，其余格子值为0。</li>
<li>通道3：食物位置。使用一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>的矩阵表示食物的位置，矩阵中食物所在的格子值为1，其余格子值为0。<br>
通过将这些信息合并到一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">3 \times 12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>的张量中，我们可以完整地表示游戏当前的状态。这样，神经网络可以通过卷积层捕捉空间信息，并对状态进行处理。</li>
</ul>
<img src="/2024/12/19/snake-3/fig1.png" srcset="/img/loading.gif" lazyload  alt="将游戏信息建模为三个矩阵" width="750" style="display: block; margin: 0 auto;"/> 
<p style="text-align: center;">图1 将游戏信息建模为三个矩阵</p>
<h3 id="网络设计">网络设计</h3>
<p>在DQN智能体中，神经网络的设计至关重要，它直接决定了智能体的学习能力和效率。我们采用了一个卷积神经网络作为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值的近似函数，专门处理输入状态张量，提取空间特征，并最终输出动作的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值。网络结构主要包括卷积层和全连接层两部分，整体结构如图2所示。</p>
<img src="/2024/12/19/snake-3/fig2.png" srcset="/img/loading.gif" lazyload  alt="神经网络结构设计" width="750" style="display: block; margin: 0 auto;"/> 
<p style="text-align: center;">图2 神经网络结构设计</p>
<p>状态特征首先进入卷积层部分。输入的状态张量具有3个通道，分别表示蛇头、蛇身和食物的位置。为了提取这一输入中的局部空间特征，我们设计了一个卷积核大小为3的卷积层，将输入3个通道映射为32个特征通道。卷积层的输出尺寸保持为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>×</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">12 \times 12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">12</span></span></span></span>。在这里，考虑到蛇头对位置十分敏感，我们采用-1作为边界填充的值，以增强智能体对边界的感知。在卷积操作后，我们使用线性整流（ReLU）激活函数，为网络引入非线性表达能力，从而帮助模型更好地拟合复杂的状态与动作价值之间的关系。<br>
卷积层的输出被展平为一维向量后，进入全连接层部分。通过一系列全连接层进一步压缩特征维度。第一层全连接层将卷积特征映射到256个隐藏单元，第二层将256映射到64，最后一层输出4个值，分别对应智能体在当前状态下每个动作（上、下、左、右）的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值。这种逐步压缩的结构能够有效提取卷积特征中的重要信息，并将其转化为动作的价值预测。<br>
我们通过创建Net类实现网络的定义，它继承自<code>torch.nn.Module</code>从而实现网络的前向传播与反向传播。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.conv = nn.Sequential(<br>            nn.ConstantPad2d(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>), <span class="hljs-comment"># 32x12x12</span><br>            nn.ReLU(),<br>        )<br>        <span class="hljs-variable language_">self</span>.fc = nn.Sequential(<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">32</span> * <span class="hljs-number">12</span> * <span class="hljs-number">12</span>, <span class="hljs-number">256</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">64</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">4</span>),<br>        )<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        feat = <span class="hljs-variable language_">self</span>.conv(x)<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.fc(feat)<br></code></pre></td></tr></table></figure>
<h3 id="智能体初始化">智能体初始化</h3>
<p>在基于DQN的智能体中，除去在5.4节中提及的超参数，我们需要额外增加了一个容量为50000的经验回放池，用于存储智能体的经验（包括状态、动作、奖励和下一状态）。这一机制允许智能体从过去的经验中学习，通过小批量采样实现数据的重复利用，减少样本间的相关性，提升学习的稳定性。<br>
DQN智能体在初始化过程中，需要创建评估网络和目标网络。评估网络用于估计当前状态下的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值，并直接参与训练；目标网络则用于生成目标<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值，其参数每隔一定的时间步从评估网络同步一次。正如<a href="https://dufolk.github.io/2024/12/19/snake-1/">前文</a>所提到的，目标网络的设计能够有效缓解训练中的不稳定性，避免目标值直接依赖自身估计而导致的发散问题。除此之外，智能体的训练使用Adam优化器更新评估网络的参数；损失函数采用均方误差，用来最小化评估网络的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值与目标<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值之间的误差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DQN</span>(nn.Module):<br>    MEMORY_SIZE = <span class="hljs-number">50000</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(DQN, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.learning_rate = <span class="hljs-number">1e-3</span><br>        <span class="hljs-variable language_">self</span>.gamma = <span class="hljs-number">0.95</span><br>        <span class="hljs-variable language_">self</span>.epsilon = <span class="hljs-number">0.1</span><br>        <span class="hljs-variable language_">self</span>.epsilon_decay = <span class="hljs-number">0.999</span><br>        <span class="hljs-variable language_">self</span>.replay_memory = []<br>        <span class="hljs-variable language_">self</span>.batch_size = <span class="hljs-number">64</span><br>        <span class="hljs-variable language_">self</span>.time_step = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.eval_net = Net()<br>        <span class="hljs-variable language_">self</span>.target_net = Net()<br>        <span class="hljs-variable language_">self</span>.init_parameters()<br>        <span class="hljs-variable language_">self</span>.optimizer = torch.optim.Adam(<span class="hljs-variable language_">self</span>.eval_net.parameters(), lr=<span class="hljs-variable language_">self</span>.learning_rate)<br>        <span class="hljs-variable language_">self</span>.loss_func = nn.MSELoss()<br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_parameters</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.BatchNorm2d):<br>                nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_target_net</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-variable language_">self</span>.target_net.load_state_dict(<span class="hljs-variable language_">self</span>.eval_net.state_dict())<br></code></pre></td></tr></table></figure>
<h3 id="获取状态">获取状态</h3>
<p>在本节中，我们通过定义<code>get_state</code>方法将游戏信息抽象成3个矩阵并堆叠起来。首先，需要对游戏是否结束进行判断，这是因为当蛇头因撞到边界而结束，会导致数组越界而产生程序错误。考虑到最后一步的 并不参与参数更新，我们可以直接返回一个全0矩阵作为占位符。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_state</span>(<span class="hljs-params">self, snake, food, done=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    构造 3x12x12 的输入张量：</span><br><span class="hljs-string">    - 通道 1：蛇头位置</span><br><span class="hljs-string">    - 通道 2：蛇身（不包括蛇头）</span><br><span class="hljs-string">    - 通道 3：食物位置</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 如果游戏结束，则返回一个全0的输入张量</span><br>    <span class="hljs-keyword">if</span> done:<br>        <span class="hljs-keyword">return</span> np.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>), dtype=np.float32)<br></code></pre></td></tr></table></figure>
<p>在确保存在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">s^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span>后，我们正常进行状态建模，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">snake_head = snake.body[<span class="hljs-number">0</span>]<br>snake_body = snake.body[<span class="hljs-number">1</span>:]<br><span class="hljs-comment"># 初始化 12x12x4 的输入张量</span><br>snake_head_matrix = np.zeros((<span class="hljs-number">12</span>, <span class="hljs-number">12</span>), dtype=np.float32) <span class="hljs-comment"># 蛇头矩阵</span><br>snake_body_matrix = np.zeros((<span class="hljs-number">12</span>, <span class="hljs-number">12</span>), dtype=np.float32) <span class="hljs-comment"># 蛇身矩阵</span><br>food_distance_matrix = np.zeros((<span class="hljs-number">12</span>, <span class="hljs-number">12</span>), dtype=np.float32) <span class="hljs-comment"># 食物距离矩阵</span><br><span class="hljs-comment"># 将蛇头和蛇身的位置映射到 12x12 的矩阵中</span><br>snake_head_matrix[snake_head.top // UNIT, snake_head.left // UNIT] = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> body <span class="hljs-keyword">in</span> snake_body:<br>    snake_body_matrix[body.top // UNIT, body.left // UNIT] = <span class="hljs-number">1</span><br><span class="hljs-comment"># 将食物位置映射到 12x12 的矩阵中</span><br>food_distance_matrix[food.rect.top // UNIT, food.rect.left // UNIT] = <span class="hljs-number">1</span> <br><span class="hljs-comment"># 将矩阵转换为 3x12x12 的输入张量</span><br>input_tensor = np.stack([snake_head_matrix, snake_body_matrix, food_distance_matrix], axis=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">return</span> input_tensor<br></code></pre></td></tr></table></figure>
<h3 id="动作选择">动作选择</h3>
<p>在动作选择过程中，基本原理与Q-learning几乎一致。唯一的区别是我们将此处使用Q-table的估计更换为使用评估网络的输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">choose_action</span>(<span class="hljs-params">self, state</span>):<br>    <span class="hljs-keyword">if</span> np.random.uniform() &lt; <span class="hljs-variable language_">self</span>.epsilon:<br>        action = np.random.choice(<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">else</span>:<br>        state = torch.tensor(state, dtype=torch.float32)<br>        state = state.unsqueeze(<span class="hljs-number">0</span>)<br>        action = np.argmax(<span class="hljs-variable language_">self</span>.forward(state).detach().numpy())<br>    <span class="hljs-keyword">return</span> action<br></code></pre></td></tr></table></figure>
<h3 id="网络训练">网络训练</h3>
<p>网络训练的核心是通过不断地从经验回放池中采样游戏状态、动作、奖励以及下一个状态，优化评估网络的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值预测，从而让智能体逐步学习到最优策略。训练过程分为三个关键步骤：存储经验、从经验中采样进行训练，以及更新目标网络的参数。<br>
首先，通过<code>store_transition</code>方法，我们将智能体每一步的交互数据存储到经验回放池中。当池子中的数据量超过设定的容量上限时，最早的数据会被移除，以确保存储的经验始终是最新的。当经验回放池中存储的数据量达到批量大小时，智能体开始从中随机采样用于训练。采样到的一批数据会被拆分为状态、动作、奖励、下一状态和终止标志，并通过张量表示形式输入到网络中。在<code>learn</code>方法中，通过评估网络预测当前状态下智能体实际选择动作的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值。智能体会通过均方误差损失函数计算评估网络的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值预测与目标<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值之间的误差，即：</p>
<p>优化器根据误差对网络参数进行更新。同时，探索率会随着时间逐步衰减，从而在训练初期更多地探索新策略，而训练后期则更加依赖当前学到的策略。</p>
<p>此外，为了提高训练的稳定性，目标网络的参数不会频繁更新，而是通过<code>update_target_net</code>方法定期从评估网络复制。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">store_transition</span>(<span class="hljs-params">self, s, a, r, s_, done</span>):<br>    <span class="hljs-comment"># 存储交互数据到经验回放池中。如果池子容量超过上限，则移除最早的数据。</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.replay_memory) &gt;= DQN.MEMORY_SIZE:<br>        <span class="hljs-variable language_">self</span>.replay_memory.pop(<span class="hljs-number">0</span>)<br>    <span class="hljs-variable language_">self</span>.replay_memory.append((s, a, r, s_, done))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">learn</span>(<span class="hljs-params">self, s, a, r, s_, done</span>):<br>    <span class="hljs-comment"># 存储当前步的交互数据</span><br>    <span class="hljs-variable language_">self</span>.store_transition(s, a, r, s_, done)<br><br>    <span class="hljs-comment"># 如果经验回放池中的数据不足一个批量，则不进行训练</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.replay_memory) &lt; <span class="hljs-variable language_">self</span>.batch_size:<br>        <span class="hljs-keyword">return</span><br><br>    <span class="hljs-comment"># 从经验回放池中随机采样一个批量的数据</span><br>    batch = random.sample(<span class="hljs-variable language_">self</span>.replay_memory, <span class="hljs-variable language_">self</span>.batch_size)<br>    s, a, r, s_, done = <span class="hljs-built_in">zip</span>(*batch)<br>    s, a, s_, r, done = np.array(s), np.array(a), np.array(s_), np.array(r), np.array(done)<br><br>    <span class="hljs-comment"># 转换为 PyTorch 张量</span><br>    s = torch.tensor(s, dtype=torch.float32)                <span class="hljs-comment"># 当前状态</span><br>    a = torch.tensor(a, dtype=torch.int64)                  <span class="hljs-comment"># 动作</span><br>    s_ = torch.tensor(s_, dtype=torch.float32)              <span class="hljs-comment"># 下一状态</span><br>    r = torch.tensor(r, dtype=torch.float32).unsqueeze(<span class="hljs-number">1</span>)   <span class="hljs-comment"># 奖励</span><br>    done = torch.tensor(done, dtype=torch.float32)          <span class="hljs-comment"># 是否结束</span><br><br>    <span class="hljs-comment"># 使用评估网络预测 Q 值，并提取实际选择动作的 Q 值</span><br>    q_predict = <span class="hljs-variable language_">self</span>.eval_net(s).gather(<span class="hljs-number">1</span>, a.unsqueeze(<span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># 计算目标 Q 值：r + γ * max(Q(s&#x27;, a&#x27;))，若终止状态则目标值为 r</span><br>    q_target = r + <span class="hljs-variable language_">self</span>.gamma * <span class="hljs-variable language_">self</span>.target_net(s_).<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].view(<span class="hljs-variable language_">self</span>.batch_size, <span class="hljs-number">1</span>) * (<span class="hljs-number">1</span> - done.unsqueeze(<span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># 计算损失并优化评估网络</span><br>    loss = <span class="hljs-variable language_">self</span>.loss_func(q_predict, q_target)<br>    <span class="hljs-variable language_">self</span>.optimizer.zero_grad()<br>    loss.backward()<br>    <span class="hljs-variable language_">self</span>.optimizer.step()<br><br>    <span class="hljs-comment"># 动态调整探索率，确保 epsilon 至少为 0.01</span><br>    <span class="hljs-variable language_">self</span>.epsilon = <span class="hljs-built_in">max</span>(<span class="hljs-variable language_">self</span>.epsilon * <span class="hljs-variable language_">self</span>.epsilon_decay, <span class="hljs-number">0.01</span>)<br>    <span class="hljs-variable language_">self</span>.time_step += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.time_step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>: <span class="hljs-comment"># 每100步更新一次目标网络</span><br>        <span class="hljs-variable language_">self</span>.update_target_net()<br></code></pre></td></tr></table></figure>
<h3 id="主程序修改">主程序修改</h3>
<p>在基于Q-learning的主程序中，我们只需将模型修改为DQN即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">MODEL = <span class="hljs-string">&#x27;DQN&#x27;</span><br></code></pre></td></tr></table></figure>
<p>在1500轮训练后，我们用折线图可视化其分数随轮数变化的曲线，如图3所示。相比与Q-learning算法，DQN由于其通过网络求取近似解的特性，性能提升速度明显更慢。但其具备的估计复杂状态下动作价值的能力依然使其具有非常高的研究和应用价值。</p>
<img src="/2024/12/19/snake-3/fig3.png" srcset="/img/loading.gif" lazyload  alt="DQN算法得分随轮次变化折线图" width="500" style="display: block; margin: 0 auto;"/> 
<p style="text-align: center;">图3 DQN算法得分随轮次变化折线图</p>
<h2 id="项目总结">项目总结</h2>
<p>本系列以贪吃蛇游戏为例，系统地展示了强化学习在自主游戏开发中的应用过程。从需求分析到项目设计，我们明确了游戏规则与环境搭建的基本逻辑；从Q-learning到DQN算法的逐步实现，我们详细阐述了强化学习智能体的核心原理与实现方法。通过状态建模与策略优化，智能体逐渐学会在复杂的游戏环境中做出合理的决策，展现了强化学习在高维动态环境中的强大学习能力。<br>
在Q-learning算法部分，我们通过表格形式存储<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值，完成了基于离散状态和动作的策略优化。尽管Q-learning算法在小规模状态空间中表现出色，但其因状态空间扩展而导致的存储和计算限制也十分明显。为此，DQN算法通过神经网络对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>值进行函数近似，成功突破了Q-learning的局限性，使智能体能够应对更复杂的状态空间。我们通过经验回放和目标网络的引入，进一步提升了DQN的训练稳定性与效率，展现了深度强化学习处理连续状态问题的优势。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%A7%91%E7%A0%94/" class="category-chain-item">科研</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/" class="print-no-link">#理论学习</a>
      
        <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" class="print-no-link">#强化学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>基于强化学习的贪吃蛇游戏(四)——基于DQN算法的智能体</div>
      <div>http://dufolk.github.io/2024/12/19/snake-3/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Dufolk</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年12月19日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/12/22/snake-4/" title="基于强化学习的贪吃蛇游戏(五)——智能体结构优化">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">基于强化学习的贪吃蛇游戏(五)——智能体结构优化</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/12/19/snake-2/" title="基于强化学习的贪吃蛇游戏(三)——基于Q-learning算法的智能体">
                        <span class="hidden-mobile">基于强化学习的贪吃蛇游戏(三)——基于Q-learning算法的智能体</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="waline"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#waline', function() {
      Fluid.utils.createCssLink('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.css')
      Fluid.utils.createScript('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.js', function() {
        var options = Object.assign(
          {"serverURL":"https://waline-six-iota.vercel.app","path":"window.location.pathname","meta":["nick","mail"],"requiredMeta":["nick"],"lang":"zh-CN","emoji":["https://unpkg.com/@waline/emojis@1.2.0/weibo"],"dark":"html[data-user-color-scheme=\"dark\"]","wordLimit":0,"pageSize":10},
          {
            el: '#waline',
            path: window.location.pathname
          }
        )
        Waline.init(options);
        Fluid.utils.waitElementVisible('#waline .vcontent', () => {
          var imgSelector = '#waline .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/scrollAnimation.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
